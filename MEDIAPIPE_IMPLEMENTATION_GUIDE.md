# üéØ Gu√≠a de Implementaci√≥n: Detecci√≥n de Manos y Rostro con MediaPipe

## ‚úÖ Cambios Implementados

### 1. **Dependencias Agregadas**
- ‚úÖ MediaPipe Tasks Vision 0.10.14
- ‚úÖ Configurado en `libs.versions.toml` y `build.gradle.kts`

### 2. **M√≥dulo de Machine Learning** (`app/src/main/java/com/example/ecohand/ml/`)
- ‚úÖ **HandDetector.kt**: Detector de manos con MediaPipe
  - Detecta hasta 2 manos simult√°neamente
  - 21 landmarks por mano
  - Modo LIVE_STREAM para tiempo real
  
- ‚úÖ **FaceDetector.kt**: Detector de rostro con MediaPipe
  - Detecta 1 rostro
  - 468 landmarks faciales
  - Modo LIVE_STREAM para tiempo real

### 3. **Componentes de Visualizaci√≥n** (`app/src/main/java/com/example/ecohand/presentation/components/`)
- ‚úÖ **DetectionOverlay.kt**: Canvas para dibujar landmarks
  - L√≠neas verdes conectando puntos
  - C√≠rculos verdes en v√©rtices
  - Conexiones anat√≥micas correctas
  
- ‚úÖ **DetectionTestScreen.kt**: Pantalla de prueba completa
  - Preview de c√°mara
  - An√°lisis de frames en tiempo real
  - Estad√≠sticas de detecci√≥n
  - Cambio entre c√°mara frontal/trasera

### 4. **Navegaci√≥n**
- ‚úÖ Ruta `Screen.DetectionTest` agregada
- ‚úÖ Integraci√≥n en `MainNavHost`
- ‚úÖ Bot√≥n en pantalla de Perfil para acceder
- ‚úÖ Bottom bar oculto en pantalla de detecci√≥n

### 5. **Assets y Documentaci√≥n**
- ‚úÖ Directorio `app/src/main/assets/` creado
- ‚úÖ Gu√≠a de descarga de modelos: `DOWNLOAD_MODELS.md`
- ‚úÖ Esta gu√≠a de implementaci√≥n

## üöÄ Pasos Siguientes

### Paso 1: Descargar Modelos de MediaPipe

**IMPORTANTE:** Los modelos NO est√°n incluidos en el c√≥digo. Debes descargarlos:

#### Opci√≥n A: Manual (Recomendado)
1. Descarga los modelos desde:
   - Hand Landmarker: https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/latest/hand_landmarker.task
   - Face Landmarker: https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task

2. Col√≥calos en: `app/src/main/assets/`
   ```
   app/
     src/
       main/
         assets/
           ‚îú‚îÄ‚îÄ hand_landmarker.task  (‚ö†Ô∏è REQUERIDO)
           ‚îî‚îÄ‚îÄ face_landmarker.task  (‚ö†Ô∏è REQUERIDO)
   ```

#### Opci√≥n B: PowerShell (Autom√°tico)
```powershell
# Ejecutar desde la ra√≠z del proyecto
$assetsPath = "app\src\main\assets"

# Descargar Hand Landmarker
Invoke-WebRequest -Uri "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/latest/hand_landmarker.task" -OutFile "$assetsPath\hand_landmarker.task"

# Descargar Face Landmarker
Invoke-WebRequest -Uri "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task" -OutFile "$assetsPath\face_landmarker.task"
```

### Paso 2: Sincronizar Gradle
```powershell
# En Android Studio, ejecuta:
# File > Sync Project with Gradle Files
```

O desde terminal:
```powershell
cd "C:\Users\herma\OneDrive\Documentos\Android proyects\ecohand"
.\gradlew build
```

### Paso 3: Ejecutar la Aplicaci√≥n
1. Conecta un dispositivo Android o inicia un emulador
2. Ejecuta la app desde Android Studio
3. Ve a: **Perfil** ‚Üí **üß™ Prueba de Detecci√≥n**
4. Concede permiso de c√°mara
5. ¬°Muestra tus manos y rostro!

## üì± Uso de la Pantalla de Detecci√≥n

### Caracter√≠sticas
- **Vista en tiempo real** de la c√°mara
- **Overlay verde** con landmarks detectados
- **Contador** de manos y rostros detectados
- **Bot√≥n** para cambiar entre c√°mara frontal/trasera
- **Estado** de los detectores (inicializados/error)

### Interpretaci√≥n Visual
- üü¢ **Puntos verdes**: Landmarks individuales (v√©rtices)
- üü¢ **L√≠neas verdes**: Conexiones entre landmarks
- **Manos**: 21 puntos por mano (mu√±eca, dedos, articulaciones)
- **Rostro**: Contorno facial, ojos, cejas, nariz, boca

### Indicadores de Estado
- ‚úÖ **"‚úì Detectores listos"**: Todo funcionando
- ‚ö†Ô∏è **"‚ö† Solo X listo"**: Un detector fall√≥
- ‚ùå **"‚úó Error al inicializar"**: Revisar modelos en assets/

## üîß Soluci√≥n de Problemas

### Error: "Model file not found"
**Causa:** Modelos no descargados o mal ubicados
**Soluci√≥n:** 
1. Verifica que existan: `app/src/main/assets/hand_landmarker.task` y `face_landmarker.task`
2. Verifica los nombres de archivo exactos (sin espacios, min√∫sculas)
3. Reconstruye el proyecto (Build > Clean Project > Rebuild Project)

### Error: "Failed to initialize detector"
**Causa:** Modelos corruptos o GPU no disponible
**Soluci√≥n:**
1. Re-descarga los modelos
2. En `HandDetector.kt` y `FaceDetector.kt`, cambia:
   ```kotlin
   .setDelegate(Delegate.GPU)
   ```
   por:
   ```kotlin
   .setDelegate(Delegate.CPU)
   ```

### Error: "Camera permission denied"
**Causa:** Permiso no concedido
**Soluci√≥n:** Toca el bot√≥n "Solicitar permiso" en la pantalla

### Detecci√≥n lenta o con lag
**Causa:** Dispositivo con recursos limitados
**Soluci√≥n:** En `DetectionTestScreen.kt`, reduce FPS:
```kotlin
val imageAnalysis = ImageAnalysis.Builder()
    .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
    .setTargetRotation(Surface.ROTATION_0)
    // Agregar:
    .setTargetResolution(Size(640, 480))
    .build()
```

### No se ven l√≠neas verdes
**Causa:** Landmarks no detectados o fuera del canvas
**Soluci√≥n:**
1. Acerca tus manos/rostro a la c√°mara
2. Mejora la iluminaci√≥n
3. Usa c√°mara frontal (mejor √°ngulo)

## üéì Pr√≥ximos Pasos (Para Reconocimiento de Se√±as)

### Fase 1: Recolecci√≥n de Datos ‚úÖ COMPLETADO
- [x] Detecci√≥n b√°sica de manos
- [x] Detecci√≥n b√°sica de rostro
- [x] Visualizaci√≥n de landmarks

### Fase 2: Almacenamiento de Patrones (Siguiente)
1. Crear entidad `PatronSenaEntity` en Room Database:
```kotlin
@Entity(tableName = "patrones_senas")
data class PatronSenaEntity(
    @PrimaryKey(autoGenerate = true)
    val id: Int = 0,
    val senaId: Int, // FK a SenaEntity
    val landmarks: String, // JSON con coordenadas
    val timestamp: Long = System.currentTimeMillis()
)
```

2. Implementar captura de patrones:
   - Bot√≥n "Guardar se√±a" en DetectionTestScreen
   - Serializar landmarks a JSON
   - Almacenar en base de datos

### Fase 3: Clasificaci√≥n de Se√±as (Futuro)
1. **Opci√≥n A - Reglas basadas en geometr√≠a:**
   - Calcular √°ngulos entre dedos
   - Detectar posiciones relativas
   - Comparar con patrones guardados

2. **Opci√≥n B - Machine Learning:**
   - Entrenar modelo TensorFlow Lite
   - Clasificar gestos en tiempo real
   - Mayor precisi√≥n para se√±as complejas

### Fase 4: Integraci√≥n en Lecciones
- Reemplazar `LeccionPracticaScreen` con detecci√≥n real
- Validar se√±as en tiempo real
- Feedback instant√°neo al usuario

## üìä Arquitectura de Detecci√≥n

```
CameraX (PreviewView)
    ‚Üì
ImageAnalysis (frame-by-frame)
    ‚Üì
Bitmap conversion
    ‚Üì
MediaPipe Detectors (Hand + Face)
    ‚Üì
Landmarks Results
    ‚Üì
DetectionOverlay (Canvas drawing)
    ‚Üì
Visual Feedback (Green lines & points)
```

## üîê Permisos Requeridos

Ya configurados en `AndroidManifest.xml`:
- ‚úÖ `android.permission.CAMERA`
- ‚úÖ `android.hardware.camera` (optional)
- ‚úÖ `android.hardware.camera.front` (optional)

## üìù Notas T√©cnicas

### Rendimiento
- **GPU acelerado** por defecto (Delegate.GPU)
- **Estrategia KEEP_ONLY_LATEST** para evitar backpressure
- **Procesamiento as√≠ncrono** con LIVE_STREAM mode
- **FPS efectivo**: ~15-30 fps (dependiendo del dispositivo)

### Precisi√≥n
- **Hand Landmarker**: 21 puntos por mano
  - 0: Mu√±eca
  - 1-4: Pulgar
  - 5-8: √çndice
  - 9-12: Medio
  - 13-16: Anular
  - 17-20: Me√±ique

- **Face Landmarker**: 468 puntos faciales
  - Contorno facial: ~35 puntos
  - Ojos: ~32 puntos (16 por ojo)
  - Boca: ~40 puntos
  - Nariz: ~9 puntos
  - Otros: ~352 puntos adicionales

### Optimizaciones Aplicadas
- ‚úÖ Modelos float16 (m√°s ligeros que float32)
- ‚úÖ Procesamiento en hilo separado (executor)
- ‚úÖ Liberaci√≥n de recursos en onDispose
- ‚úÖ Detecci√≥n solo cuando detectores est√°n listos

## üé® Personalizaci√≥n

### Cambiar color de las l√≠neas
En `DetectionOverlay.kt`:
```kotlin
val lineColor = Color(0xFF00FF00) // Verde brillante
// Cambiar a:
val lineColor = Color(0xFFFF0000) // Rojo
```

### Ajustar grosor de l√≠neas
```kotlin
val lineWidth = 3f
// Cambiar a:
val lineWidth = 5f // M√°s grueso
```

### Cambiar tama√±o de puntos
```kotlin
val pointRadius = 6f
// Cambiar a:
val pointRadius = 8f // M√°s grande
```

### Detectar m√°s manos
En `HandDetector.kt`:
```kotlin
maxNumHands: Int = 2
// Cambiar a:
maxNumHands: Int = 4 // Detectar hasta 4 manos
```

## ‚ú® Resultado Esperado

Al abrir la pantalla de prueba, deber√≠as ver:
1. ‚úÖ Vista de c√°mara en tiempo real
2. ‚úÖ L√≠neas verdes dibujadas sobre tus manos (si las muestras)
3. ‚úÖ Puntos verdes en articulaciones y dedos
4. ‚úÖ Contorno facial con l√≠neas verdes
5. ‚úÖ Contador actualizado: "üëê Manos: 2" y "üòä Rostros: 1"

**¬°La detecci√≥n est√° funcionando correctamente!** üéâ

---

## üìû Contacto y Soporte

Si encuentras problemas:
1. Revisa los logs en Logcat (filtro: `HandDetector`, `FaceDetector`)
2. Verifica que los modelos est√©n en `app/src/main/assets/`
3. Aseg√∫rate de que la app tenga permiso de c√°mara
4. Prueba en un dispositivo real (mejor rendimiento que emulador)

---

**Desarrollado con ‚ù§Ô∏è para EcoHand**
*Aprendizaje de Lengua de Se√±as Peruanas*

